{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Classificação Binaria Brest Cancer.ipynb",
      "provenance": [],
      "mount_file_id": "12nDeXJ6f7wtA0aVaxgu3P463pxkrH2Qg",
      "authorship_tag": "ABX9TyOkYsJXW2PQcQd6lbDcASlA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KillerGlass/classifica-o-binaria-em-pytroch/blob/main/Classifica%C3%A7%C3%A3o_Binaria_Brest_Cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TuR6dcIl7bF"
      },
      "source": [
        "# Etapa 1: Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eAXNfGLmAJO"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score #matriz de confusão"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2FGNiTUHmUI9",
        "outputId": "1a15d7f4-68e5-4380-db83-00af730f09b9"
      },
      "source": [
        "import torch\n",
        "torch.__version__\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.9.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8KmOFZwmUS0"
      },
      "source": [
        "import torch.nn as nn #pacote de redes neurais"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaIrlVlNw7N7"
      },
      "source": [
        "# Etapa 2: Base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BndPORHcmUXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d9716b8-89a0-4ef7-f677-47f68c723ca3"
      },
      "source": [
        "np.random.seed(123)\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f0299ae4070>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP5jfON7mUa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e98cb8-8e38-4653-f6ff-93158c86667c"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScWaIHjvx4vC"
      },
      "source": [
        "prev = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Deep Learnig/Bases/entradas_breast.csv')\n",
        "target = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Deep Learnig/Bases/saidas_breast.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8JNUOwgyOGu",
        "outputId": "1ac375bb-e4d9-4127-9482-e9d89031aee0"
      },
      "source": [
        "prev.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "R75C52o0yOOh",
        "outputId": "ff5fdd1d-e694-4006-af3e-dc17489902b2"
      },
      "source": [
        "prev.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave_points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave_points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1095.0000</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8589.0</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3398.0</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>186.0000</td>\n",
              "      <td>275.0000</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4585.0</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>243.0000</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1156.0000</td>\n",
              "      <td>3445.0</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>173.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>198.0000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5438.0</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>205.0000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    radius_mean   texture_mean  ...   symmetry_worst   fractal_dimension_worst\n",
              "0         17.99          10.38  ...           0.4601                   0.11890\n",
              "1         20.57          17.77  ...         275.0000                   0.08902\n",
              "2         19.69          21.25  ...           0.3613                   0.08758\n",
              "3         11.42          20.38  ...           0.6638                 173.00000\n",
              "4         20.29          14.34  ...           0.2364                   0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr5mkOVZyWyZ",
        "outputId": "f268ddc1-4ddc-42d7-faae-3b4631cefb50"
      },
      "source": [
        "np.unique(target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "naj9baTvyW8x",
        "outputId": "fd7b6f3b-f187-4e5a-e2ac-8d05ef005f6c"
      },
      "source": [
        "sns.countplot(target['0'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f02932cda50>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn3qupS4ymsa"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(prev,\n",
        "                                                    target,\n",
        "                                                    test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY6hdwiQymwM",
        "outputId": "79141669-ca36-4c3e-f813-b9c0e8f0910d"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(426, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEnl_s59xAuu"
      },
      "source": [
        "# Etapa 3: Tranformação dos dados para tensores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddD2KAU_yjNj",
        "outputId": "3ab493b6-17cc-4079-adc2-3de497a364fd"
      },
      "source": [
        "type(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE3ozmx3ymI4"
      },
      "source": [
        "#deve se tranforma os dados em tensores\n",
        "#primeiro eh preciso converter para numpy array\n",
        "def transform_type(dados):\n",
        "  return torch.tensor(np.array(dados),dtype=torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhCyl4zbyjUT"
      },
      "source": [
        "x_train = transform_type(x_train)\n",
        "y_train = transform_type(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WadXLTARyjZG",
        "outputId": "43d2c5ac-ff3d-479e-91fe-0b4ec4946bb8"
      },
      "source": [
        "type(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQrr2gygyjbm"
      },
      "source": [
        "#criando o dataset\n",
        "dataset =  torch.utils.data.TensorDataset(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA1iGdPOzuw4",
        "outputId": "2623952d-eb03-4f45-99bd-c669965246cd"
      },
      "source": [
        "type(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataset.TensorDataset"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBM8oRFyz1AH"
      },
      "source": [
        "#batch size defini o tamanho do lote a ser enviado a cada interação\n",
        "train = torch.utils.data.DataLoader(dataset,batch_size=10, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQJYUZ44xGWC"
      },
      "source": [
        "# Etapa 4: Construção do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOvQH79T0LsS"
      },
      "source": [
        "# 30 neuronios na camada de entrada, pois temos 30 atributos\n",
        "# duas camadas ocultas, com 16 neuronios\n",
        "# na ultima camada, apenas 1 neuronio, sendo esse um problema de classificação\n",
        "#para se saber o numero de neuronios a ser decedido nas camadas ocultas\n",
        "#soma os neuronios de entrada com os de saida e dividi por 2\n",
        "# 30 neuronios de entrada + 1 de saida / 2 = 15,5, arredondando 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGFmYReB0Lvx"
      },
      "source": [
        "classificador = nn.Sequential(\n",
        "    nn.Linear(in_features=30,out_features=16),\n",
        "    nn.ReLU(),#função de ativação entre camadas\n",
        "    nn.Linear(in_features=16,out_features=16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(in_features=16,out_features=1),\n",
        "    nn.Sigmoid()#função de ativação na saida\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLlOsePn0Lzc",
        "outputId": "77fdb741-caf6-49af-8a93-d2072a15977c"
      },
      "source": [
        "classificador.parameters#bias signifca criação de neuronios extras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Sequential(\n",
              "  (0): Linear(in_features=30, out_features=16, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb2qvue_2eQK"
      },
      "source": [
        "criterio = nn.BCELoss()#funçao de perda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWzlvpwF2kWT"
      },
      "source": [
        "#função de ativação, weight_decay é um parametro para aproximar o valor de aprendizado\n",
        "#do gradiente, diminuindo seu valor\n",
        "optimizer = torch.optim.Adam(classificador.parameters(),lr=0.001,weight_decay=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMaMQuQLxK1a"
      },
      "source": [
        "# Etapa 5: Treinamento do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJWj3zRj3N60"
      },
      "source": [
        "#keras utiliza o fit\n",
        "#pytorch utliza um for manual\n",
        "#batch_size eh de 10 e temos 426 registros, assim os ajustes de peso\n",
        "#sera feito 42,6 vezes a cada epoca, ou seja essas serão as iterações"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYfhi7-s3N-B",
        "outputId": "33405da2-0996-4c44-a6ca-eb20d4525d52"
      },
      "source": [
        "for epoch in range(100):\n",
        "  running_loss = 0\n",
        "\n",
        "  for data in train:\n",
        "    #inputs sao entradas, previsores. Labels as respostas reais\n",
        "    inputs, labels = data\n",
        "    #zerando os gradientes. Gradientes é a direção para onde vai ser feito os ajustes do peso\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = classificador(inputs)#classificador.forward é a mesma coisa, camada de aprendizado\n",
        "\n",
        "    loss = criterio(outputs,labels)#calculando o erro\n",
        "\n",
        "    #forward camada para frente q faz os caluculos, o backpropagation voltar para tras atualizando os pesos\n",
        "    #backward atualiza os pesos\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  \n",
        "  #a divisao ocorre para ter uma proporção de erro\n",
        "  print(\"Epocas: {} | Loss: {:.5f}\".format(epoch+1,running_loss/len(train)))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epocas: 1 | Loss: 0.20397\n",
            "Epocas: 2 | Loss: 0.17628\n",
            "Epocas: 3 | Loss: 0.31377\n",
            "Epocas: 4 | Loss: 0.17958\n",
            "Epocas: 5 | Loss: 0.21617\n",
            "Epocas: 6 | Loss: 0.18558\n",
            "Epocas: 7 | Loss: 0.26513\n",
            "Epocas: 8 | Loss: 0.20045\n",
            "Epocas: 9 | Loss: 0.17075\n",
            "Epocas: 10 | Loss: 0.25806\n",
            "Epocas: 11 | Loss: 0.17693\n",
            "Epocas: 12 | Loss: 0.21039\n",
            "Epocas: 13 | Loss: 0.17759\n",
            "Epocas: 14 | Loss: 0.18450\n",
            "Epocas: 15 | Loss: 0.17098\n",
            "Epocas: 16 | Loss: 0.15548\n",
            "Epocas: 17 | Loss: 0.16413\n",
            "Epocas: 18 | Loss: 0.18054\n",
            "Epocas: 19 | Loss: 0.16007\n",
            "Epocas: 20 | Loss: 0.17021\n",
            "Epocas: 21 | Loss: 0.15464\n",
            "Epocas: 22 | Loss: 0.19277\n",
            "Epocas: 23 | Loss: 0.17958\n",
            "Epocas: 24 | Loss: 0.22267\n",
            "Epocas: 25 | Loss: 0.18797\n",
            "Epocas: 26 | Loss: 0.15500\n",
            "Epocas: 27 | Loss: 0.17337\n",
            "Epocas: 28 | Loss: 0.15709\n",
            "Epocas: 29 | Loss: 0.21127\n",
            "Epocas: 30 | Loss: 0.14801\n",
            "Epocas: 31 | Loss: 0.16485\n",
            "Epocas: 32 | Loss: 0.17852\n",
            "Epocas: 33 | Loss: 0.17664\n",
            "Epocas: 34 | Loss: 0.16889\n",
            "Epocas: 35 | Loss: 0.14063\n",
            "Epocas: 36 | Loss: 0.17311\n",
            "Epocas: 37 | Loss: 0.16739\n",
            "Epocas: 38 | Loss: 0.19526\n",
            "Epocas: 39 | Loss: 0.15418\n",
            "Epocas: 40 | Loss: 0.14358\n",
            "Epocas: 41 | Loss: 0.18135\n",
            "Epocas: 42 | Loss: 0.17141\n",
            "Epocas: 43 | Loss: 0.13831\n",
            "Epocas: 44 | Loss: 0.20054\n",
            "Epocas: 45 | Loss: 0.14047\n",
            "Epocas: 46 | Loss: 0.14549\n",
            "Epocas: 47 | Loss: 0.25844\n",
            "Epocas: 48 | Loss: 0.16898\n",
            "Epocas: 49 | Loss: 0.15254\n",
            "Epocas: 50 | Loss: 0.13431\n",
            "Epocas: 51 | Loss: 0.21270\n",
            "Epocas: 52 | Loss: 0.25874\n",
            "Epocas: 53 | Loss: 0.17610\n",
            "Epocas: 54 | Loss: 0.15042\n",
            "Epocas: 55 | Loss: 0.18682\n",
            "Epocas: 56 | Loss: 0.13166\n",
            "Epocas: 57 | Loss: 0.13702\n",
            "Epocas: 58 | Loss: 0.13226\n",
            "Epocas: 59 | Loss: 0.13893\n",
            "Epocas: 60 | Loss: 0.13443\n",
            "Epocas: 61 | Loss: 0.13898\n",
            "Epocas: 62 | Loss: 0.11681\n",
            "Epocas: 63 | Loss: 0.13300\n",
            "Epocas: 64 | Loss: 0.12938\n",
            "Epocas: 65 | Loss: 0.11404\n",
            "Epocas: 66 | Loss: 0.14886\n",
            "Epocas: 67 | Loss: 0.16384\n",
            "Epocas: 68 | Loss: 0.13884\n",
            "Epocas: 69 | Loss: 0.14279\n",
            "Epocas: 70 | Loss: 0.15412\n",
            "Epocas: 71 | Loss: 0.13425\n",
            "Epocas: 72 | Loss: 0.13121\n",
            "Epocas: 73 | Loss: 0.14134\n",
            "Epocas: 74 | Loss: 0.14534\n",
            "Epocas: 75 | Loss: 0.16559\n",
            "Epocas: 76 | Loss: 0.14002\n",
            "Epocas: 77 | Loss: 0.10980\n",
            "Epocas: 78 | Loss: 0.14252\n",
            "Epocas: 79 | Loss: 0.12874\n",
            "Epocas: 80 | Loss: 0.14883\n",
            "Epocas: 81 | Loss: 0.12006\n",
            "Epocas: 82 | Loss: 0.11132\n",
            "Epocas: 83 | Loss: 0.10735\n",
            "Epocas: 84 | Loss: 0.13579\n",
            "Epocas: 85 | Loss: 0.12662\n",
            "Epocas: 86 | Loss: 0.12740\n",
            "Epocas: 87 | Loss: 0.15443\n",
            "Epocas: 88 | Loss: 0.17311\n",
            "Epocas: 89 | Loss: 0.12847\n",
            "Epocas: 90 | Loss: 0.13982\n",
            "Epocas: 91 | Loss: 0.14574\n",
            "Epocas: 92 | Loss: 0.24319\n",
            "Epocas: 93 | Loss: 0.13378\n",
            "Epocas: 94 | Loss: 0.14398\n",
            "Epocas: 95 | Loss: 0.12787\n",
            "Epocas: 96 | Loss: 0.12770\n",
            "Epocas: 97 | Loss: 0.11707\n",
            "Epocas: 98 | Loss: 0.11817\n",
            "Epocas: 99 | Loss: 0.12157\n",
            "Epocas: 100 | Loss: 0.15711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBYMofa4xQgy"
      },
      "source": [
        "# Etapa 6: Validação dos *pesos*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIksquZ473DN"
      },
      "source": [
        "#aprendizado de uma rede neural é a escolha dos melhores pesos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIntuHjd73M2",
        "outputId": "39319537-90c1-439b-ad5f-916e4d7d9b16"
      },
      "source": [
        "params = list(classificador.parameters())\n",
        "params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-1.0512e-01,  1.0203e-02, -2.1697e-01,  9.8775e-02, -1.0516e-01,\n",
              "           7.7038e-02,  3.6920e-01, -2.8992e-01, -3.6031e-01,  2.6285e-01,\n",
              "           2.7225e-02,  1.0517e-01,  8.8305e-02,  6.7382e-02,  5.7505e-03,\n",
              "          -3.0764e-01, -2.6443e-01, -2.5316e-01,  5.0114e-01,  1.8472e-01,\n",
              "          -5.2942e-01,  8.5157e-02, -1.7406e-01,  8.0123e-02, -9.2698e-02,\n",
              "          -5.5577e-02, -1.6607e-01, -1.9344e-01, -3.0759e-02,  2.7663e-01],\n",
              "         [-3.6154e-02, -1.2858e-01,  2.0944e-01,  1.2281e-01, -2.6734e-02,\n",
              "           2.0003e-01,  2.9778e-02,  6.1997e-02,  2.2707e-01, -4.4835e-03,\n",
              "           1.4191e-02, -5.8470e-02,  1.3047e-01,  7.9025e-02, -1.6688e-02,\n",
              "          -5.9752e-03,  4.0820e-01,  2.0353e-01,  5.1408e-01, -1.9351e-01,\n",
              "           1.6715e-01, -3.0923e-01, -2.7031e-02, -1.2323e-01, -2.4949e-01,\n",
              "          -1.0567e-01, -2.1590e-01,  1.6212e-01,  1.5927e-01, -3.5946e-01],\n",
              "         [ 1.1285e-01,  3.7720e-01, -4.1670e-02, -1.2636e-01,  9.6187e-03,\n",
              "          -2.1205e-02, -3.8477e-02,  1.7012e-02,  2.3018e-01, -5.1919e-02,\n",
              "          -9.3453e-02, -3.1303e-02, -1.7458e-01, -2.4891e-01,  1.7425e-03,\n",
              "           2.1377e-01, -2.2316e-02,  1.2747e-01, -6.4323e-01,  5.1739e-04,\n",
              "           1.5302e-01,  5.1588e-02,  1.6196e-01,  1.2330e-01,  2.2897e-01,\n",
              "           2.5887e-01,  1.6678e-01, -2.3806e-01, -3.1234e-01,  6.4438e-04],\n",
              "         [ 2.1601e-01, -8.4254e-02,  4.0214e-01,  4.9143e-02, -4.1152e-01,\n",
              "          -3.1787e-01, -2.7094e-01,  1.9779e-01,  1.6389e-01,  6.1041e-02,\n",
              "          -1.0555e-01,  7.5691e-02,  1.0327e-01, -1.5148e-01, -1.4800e-02,\n",
              "           3.2065e-01,  4.4275e-01,  3.0035e-01, -5.2081e-01, -1.9471e-01,\n",
              "           2.2188e-01,  3.1520e-02,  1.6921e-01, -1.0201e-01,  8.9188e-02,\n",
              "          -6.2689e-02,  3.2620e-01,  6.6454e-02,  5.1851e-02, -1.6084e-01],\n",
              "         [ 4.8652e-01, -1.0147e-01,  4.3948e-01,  1.1826e-01, -3.3113e-01,\n",
              "           6.7773e-02, -4.6577e-02,  1.4694e-01, -1.0650e-01, -4.3507e-02,\n",
              "           1.3460e-02,  1.1279e-02,  6.0154e-02, -3.1376e-01, -2.5302e-02,\n",
              "           3.6316e-01,  6.0287e-01,  5.3271e-01, -2.2770e-01, -2.6531e-01,\n",
              "           1.3753e-01, -3.9385e-03,  1.8918e-01, -1.4830e-01, -8.8523e-02,\n",
              "          -3.6249e-02, -8.5175e-03, -2.1258e-01, -3.4692e-02, -1.6018e-01],\n",
              "         [-7.5527e-04,  8.0664e-03,  5.4484e-02, -5.9096e-02,  7.2171e-02,\n",
              "           1.2742e-01,  6.4761e-02, -8.2356e-30, -8.1578e-02, -1.1989e-28,\n",
              "           1.4025e-28, -8.4447e-02, -1.6707e-02,  1.3891e-01,  2.0384e-29,\n",
              "           6.9988e-29,  2.2119e-28, -5.5462e-29, -3.8188e-30,  3.0004e-29,\n",
              "          -4.8510e-03,  4.6857e-03,  1.0024e-02, -4.8475e-02,  1.3098e-02,\n",
              "          -4.1238e-04,  8.2570e-02, -1.8417e-28,  3.9829e-28,  6.9752e-29],\n",
              "         [-6.0243e-06, -2.8608e-03,  2.7965e-02, -7.5737e-03,  3.4192e-39,\n",
              "           6.1298e-39, -1.0025e-39,  5.4933e-40,  1.9733e-39, -1.1130e-39,\n",
              "           2.5812e-39, -3.7281e-02, -7.8567e-02, -2.8973e-03,  4.6568e-39,\n",
              "          -4.6501e-40, -5.9242e-39,  1.3890e-39,  4.8237e-39,  2.2226e-39,\n",
              "           8.9472e-02,  2.1266e-04, -3.2735e-03, -7.0461e-02, -2.1717e-39,\n",
              "          -5.2042e-39,  2.8937e-39, -5.0025e-39, -1.8748e-40, -5.7393e-39],\n",
              "         [-8.2072e-02, -1.2994e-01, -2.0552e-01,  8.4755e-02, -3.8947e-02,\n",
              "          -2.5119e-01, -1.2830e-01, -1.0007e-01, -7.0716e-01, -1.1776e-01,\n",
              "          -1.2428e-01,  1.1720e-01,  6.1182e-04,  1.5148e-01,  1.4794e-02,\n",
              "           3.3960e-02, -3.0402e-01,  2.4223e-02, -8.6533e-02,  6.6000e-02,\n",
              "           9.1444e-02,  1.4477e-03, -6.2641e-02, -1.0754e-01,  1.8378e-01,\n",
              "          -1.7806e-01, -5.2072e-01, -3.9330e-01,  5.5435e-02,  1.2923e-01],\n",
              "         [ 1.9764e-01,  2.0275e-01,  3.3578e-01, -1.8774e-01,  3.9936e-01,\n",
              "          -7.9148e-02,  2.9125e-01,  2.2381e-01, -6.3273e-01,  8.0588e-02,\n",
              "           1.6384e-01,  3.0646e-02,  5.3840e-02, -2.5546e-01,  5.2089e-03,\n",
              "          -2.3142e-02,  1.9321e-02,  7.9235e-03, -4.5605e-01, -2.2047e-01,\n",
              "           7.1720e-02, -1.3638e-01,  2.0161e-01, -1.9133e-01,  5.2165e-01,\n",
              "          -6.1551e-02,  2.8119e-01,  8.4326e-02,  1.1658e-01, -1.5072e-01],\n",
              "         [ 3.5295e-01,  1.5373e-01,  2.7028e-01,  1.7548e-01,  3.6395e-02,\n",
              "           2.7553e-01,  1.3642e-02,  2.8583e-01, -1.4637e-01, -3.7699e-01,\n",
              "          -7.1068e-02,  1.1906e-01, -3.2410e-02, -2.9016e-01, -1.2141e-02,\n",
              "           2.3633e-01,  4.9661e-01,  4.1065e-01, -4.0649e-01, -1.0691e-01,\n",
              "           2.2194e-01, -1.3041e-01,  3.5394e-02, -1.1063e-01, -3.4108e-01,\n",
              "          -5.9507e-02,  2.0679e-01, -1.4059e-01,  7.5696e-02, -4.0010e-01],\n",
              "         [-4.4411e-01, -2.5502e-02, -3.2564e-01, -1.6691e-01,  3.8305e-01,\n",
              "           2.5346e-01, -1.7629e-01, -1.3451e-01, -5.8286e-02, -2.0847e-01,\n",
              "           1.7561e-01,  2.0176e-02,  1.0444e-01,  1.3726e-02,  1.3820e-02,\n",
              "           2.4399e-02, -6.4551e-01, -1.6480e-01,  1.4701e-01,  1.4136e-01,\n",
              "           1.7252e-02,  3.1004e-01, -1.3526e-01,  1.3047e-01,  5.5819e-02,\n",
              "           2.8783e-02,  6.4958e-02, -1.7776e-02,  9.8814e-02,  3.9160e-01],\n",
              "         [-1.6908e-02, -5.0789e-01,  2.1268e-01, -1.1237e-01, -5.4932e-02,\n",
              "          -3.8959e-01,  1.1265e-01, -1.5254e-01, -2.1844e-02,  2.0444e-02,\n",
              "           2.2596e-01, -1.3245e-01,  1.0224e-01,  7.6461e-02, -2.0360e-02,\n",
              "          -1.6713e-02,  2.4287e-01, -2.1330e-02,  6.5783e-01, -1.1660e-02,\n",
              "           9.0221e-02, -2.9950e-01,  2.2015e-01, -7.4540e-02, -6.9078e-01,\n",
              "           4.2839e-01, -4.2504e-02, -3.0662e-02, -1.5112e-01, -9.5979e-03],\n",
              "         [-3.6404e-01, -8.2160e-02, -3.5469e-01, -1.2816e-01, -6.6842e-02,\n",
              "          -1.2821e-01,  1.3464e-01, -3.0398e-02,  7.1866e-02, -1.6328e-01,\n",
              "          -1.5403e-01,  9.0364e-03,  1.2817e-01, -7.3520e-02,  1.7128e-02,\n",
              "          -2.6717e-03, -3.5844e-01, -1.6680e-01, -3.6683e-01,  1.9012e-01,\n",
              "           4.5589e-02,  3.8235e-03, -2.4157e-01, -2.2368e-02,  1.5292e-01,\n",
              "           2.4087e-01,  1.7115e-02,  2.3626e-02, -9.0894e-02,  3.7728e-01],\n",
              "         [ 1.0726e-01,  2.6950e-01,  2.8625e-01, -4.2875e-02,  2.2899e-02,\n",
              "          -1.1438e-01, -2.2487e-02, -8.7458e-02,  2.6632e-01, -2.9077e-01,\n",
              "          -1.8274e-01, -1.0340e-02, -1.4967e-01,  1.6133e-01,  2.8732e-03,\n",
              "           1.8550e-01, -3.0452e-02,  2.3767e-01, -6.5386e-01,  1.4779e-03,\n",
              "           1.6547e-01,  1.1024e-01,  5.1504e-02, -1.7760e-02,  1.7346e-01,\n",
              "           2.2162e-01,  3.1415e-01,  1.2945e-02, -8.5044e-02,  7.4633e-03],\n",
              "         [-3.0560e-01, -1.5495e-01, -3.2121e-01,  1.1371e-01,  1.5301e-01,\n",
              "          -3.3747e-02,  5.1042e-02, -2.0224e-02, -1.5798e-02, -4.6505e-01,\n",
              "          -1.4767e-01, -1.0311e-01,  1.0029e-01,  1.2330e-01,  2.1572e-02,\n",
              "           5.3239e-02, -4.9847e-01, -3.2511e-01, -1.7053e-02,  1.8359e-01,\n",
              "          -5.2404e-03,  1.0664e-02, -3.3903e-01,  1.5204e-01,  8.5890e-02,\n",
              "          -5.6683e-03,  1.0782e-01,  6.6602e-02,  1.1988e-01,  2.2940e-01],\n",
              "         [ 1.5570e-01,  6.7447e-02,  3.5979e-01,  2.4429e-02, -5.3219e-01,\n",
              "          -4.1769e-01,  1.5333e-01,  6.5425e-02, -9.8824e-03,  3.4211e-01,\n",
              "          -1.1940e-01, -2.2736e-01,  3.4937e-02, -2.1834e-02,  2.2837e-03,\n",
              "          -3.2200e-02, -3.4038e-02,  2.5448e-01,  4.6999e-01, -1.5810e-03,\n",
              "           3.3658e-03, -1.4212e-01, -4.7315e-02, -2.9141e-02,  3.1114e-01,\n",
              "           1.3766e-01, -1.9204e-01, -6.1277e-02, -2.1722e-02,  2.5454e-02]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([-6.2854e-01,  3.1596e-01,  1.4810e-01,  7.0983e-01,  7.5296e-01,\n",
              "          4.3385e-13, -1.9364e-39, -9.2957e-02,  3.7138e-01,  3.9076e-01,\n",
              "         -6.2233e-01,  2.5291e-01, -4.4694e-01,  2.5397e-01, -5.7841e-01,\n",
              "          4.2139e-01], requires_grad=True), Parameter containing:\n",
              " tensor([[-1.1291e-01,  1.3403e-01, -1.6864e-01,  9.4588e-02, -2.0512e-01,\n",
              "          -2.4960e-02,  2.1900e-03,  1.4739e-01, -1.4711e-02, -3.2248e-02,\n",
              "          -1.5955e-02,  1.4193e-01, -1.2950e-01, -1.2066e-02, -2.0329e-01,\n",
              "           1.3147e-01],\n",
              "         [-1.5199e-01, -3.7375e-02, -1.7583e-02, -6.8777e-02,  1.4173e-01,\n",
              "          -5.5693e-39,  1.2522e-01,  3.8818e-02,  1.0399e-39, -2.2848e-02,\n",
              "          -2.2662e-02, -2.0069e-02, -1.6892e-01, -1.9528e-02,  8.5576e-02,\n",
              "          -6.1018e-02],\n",
              "         [ 5.7820e-02, -3.9299e-02,  2.0435e-02,  9.8686e-02,  9.9772e-02,\n",
              "           4.9953e-39,  1.8807e-39, -1.9840e-01,  3.4677e-01, -8.7767e-02,\n",
              "          -3.1057e-01, -2.2870e-01,  4.5205e-02,  5.3570e-02, -3.5966e-02,\n",
              "           2.8852e-01],\n",
              "         [-1.9190e-02, -1.2626e-02, -7.6606e-07, -1.5647e-02, -7.8555e-03,\n",
              "          -2.2557e-40, -2.5938e-39, -2.0498e-03, -6.0821e-39, -5.3661e-03,\n",
              "          -1.0500e-02, -4.8621e-03, -8.0585e-03, -1.0164e-09, -1.3906e-02,\n",
              "          -2.2355e-03],\n",
              "         [ 1.1134e-01, -2.2667e-01,  8.6712e-02,  1.9774e-01,  3.7993e-02,\n",
              "          -5.3506e-40,  1.6715e-01, -2.0319e-01,  1.1157e-01,  7.1507e-03,\n",
              "          -3.0460e-02,  5.7009e-02,  1.6659e-01,  7.2484e-03, -1.3859e-01,\n",
              "           8.6029e-02],\n",
              "         [-6.5314e-12, -8.4653e-11, -6.9633e-39, -6.4080e-11, -6.4481e-21,\n",
              "           5.8219e-39, -1.5602e-39, -5.9610e-39,  4.5427e-39, -4.5307e-40,\n",
              "          -3.3780e-22, -5.6213e-30, -5.6182e-17, -2.1645e-40, -8.5632e-12,\n",
              "           2.0194e-39],\n",
              "         [-2.6233e-02, -5.6120e-03, -1.8411e-02, -1.9886e-02, -1.3192e-02,\n",
              "          -6.2881e-39,  1.7612e-40, -3.1726e-02,  2.4915e-03, -4.0723e-02,\n",
              "          -1.4732e-02,  1.6534e-02, -1.7304e-02, -1.7071e-09, -5.1483e-03,\n",
              "           1.7046e-02],\n",
              "         [-1.4531e-01, -1.5981e-01,  1.2087e-01, -3.5983e-02,  2.3509e-01,\n",
              "           2.9365e-02, -1.8935e-01,  2.3534e-02,  2.6585e-01,  1.8649e-01,\n",
              "          -2.2285e-02, -1.0156e-01,  1.7132e-01,  1.7377e-01, -1.8557e-02,\n",
              "           2.4541e-03],\n",
              "         [ 1.4850e-01,  6.6449e-02, -1.2340e-01, -1.9914e-01,  5.4427e-02,\n",
              "          -2.4890e-01,  1.1319e-01,  2.7954e-01, -4.2140e-01,  1.3079e-01,\n",
              "          -1.5739e-01, -3.0229e-02, -4.8561e-03,  1.0424e-01,  1.4381e-01,\n",
              "          -1.0578e-02],\n",
              "         [-5.4393e-03,  7.5259e-07,  2.9275e-02, -5.5436e-03, -4.5017e-03,\n",
              "          -6.4212e-40, -6.6292e-39, -2.5853e-02, -3.6632e-02, -2.8910e-02,\n",
              "          -4.7734e-03, -2.8982e-03, -4.6805e-03, -2.0227e-02,  8.9872e-03,\n",
              "           8.2116e-03],\n",
              "         [-8.3931e-02, -1.4483e-01, -1.8377e-01,  2.6876e-02, -1.7233e-01,\n",
              "           1.7558e-01, -6.1120e-40,  4.7633e-02,  4.7508e-39,  3.7620e-02,\n",
              "          -6.5720e-03,  1.9662e-01, -7.6687e-03, -2.3942e-02,  3.7217e-02,\n",
              "          -1.1391e-01],\n",
              "         [ 9.3073e-02,  1.7869e-01,  2.8615e-03, -1.7173e-01, -1.8993e-02,\n",
              "          -1.1134e-01,  1.4312e-01,  1.1121e-01,  1.7284e-01, -2.6003e-01,\n",
              "           5.1894e-02, -8.9191e-02,  1.8900e-01, -1.7541e-02, -1.0930e-01,\n",
              "          -1.8222e-01],\n",
              "         [-1.0616e-01,  3.5660e-02, -5.8918e-02,  1.6083e-01,  2.3333e-01,\n",
              "           1.4215e-02,  6.6613e-03,  1.7816e-01,  2.3882e-01,  1.8104e-01,\n",
              "          -2.1863e-01,  1.6185e-01, -1.1083e-01,  2.6239e-01,  6.3321e-02,\n",
              "           5.2202e-02],\n",
              "         [ 7.5004e-02, -1.8542e-01, -1.8579e-01,  8.2116e-02, -4.7253e-02,\n",
              "           1.5298e-01,  3.4785e-39,  6.3442e-02, -2.1434e-01,  7.1094e-02,\n",
              "          -1.5382e-01, -3.6232e-01,  8.9429e-02,  2.1454e-01,  1.1679e-01,\n",
              "          -1.0582e-01],\n",
              "         [ 1.4429e-01,  1.2836e-01, -2.5300e-01, -4.5498e-02,  1.7290e-01,\n",
              "          -6.6612e-03,  5.6629e-41, -1.4397e-02,  3.5397e-01, -1.9984e-01,\n",
              "          -2.1075e-01,  1.3435e-01, -1.3888e-01,  5.3457e-02, -2.6286e-01,\n",
              "          -1.8769e-01],\n",
              "         [-1.8188e-01, -2.1902e-01,  1.5170e-01,  1.9286e-01, -1.4330e-01,\n",
              "          -1.2810e-01, -1.9667e-01,  1.5251e-01, -2.0457e-02, -1.2964e-01,\n",
              "           2.1048e-01,  1.3344e-01,  8.9043e-02, -7.2917e-02,  2.2270e-01,\n",
              "          -9.3958e-02]], requires_grad=True), Parameter containing:\n",
              " tensor([-2.0014e-02, -5.8890e-03,  1.9673e-01, -2.3415e-39,  7.4314e-01,\n",
              "          4.9349e-40, -6.8208e-07,  2.9325e-01, -5.3389e-01, -4.6386e-03,\n",
              "          1.2552e-03, -3.2250e-02,  6.5716e-01, -3.0264e-01, -2.2282e-01,\n",
              "         -4.6285e-01], requires_grad=True), Parameter containing:\n",
              " tensor([[-3.2222e-03, -5.9038e-02,  1.3421e-01,  2.4429e-02,  3.9868e-02,\n",
              "           6.4001e-40, -5.3644e-03,  2.3099e-01, -9.7797e-02, -3.7922e-03,\n",
              "           6.1840e-02, -1.7772e-02,  1.6184e-01, -1.0263e-01, -1.5311e-01,\n",
              "          -1.0742e-01]], requires_grad=True), Parameter containing:\n",
              " tensor([0.9173], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6ZCh11W8NWJ",
        "outputId": "fc695f46-8447-41ca-a813-774920cc39de"
      },
      "source": [
        "pesos = params[0]\n",
        "pesos.shape\n",
        "#esses sao os pesos da camada de entrada para camada de oculta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vY3msXH8rid",
        "outputId": "c4944207-14c0-41b4-d46d-b39a61562d7c"
      },
      "source": [
        "bias = params[1]\n",
        "bias.shape\n",
        "#sao os pesos de uma so camada"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpQ8zwWX8roz",
        "outputId": "c9dbc35e-7696-4014-c429-3826f1ffff48"
      },
      "source": [
        "pesos1 = params[2]\n",
        "pesos1.shape\n",
        "#esses sao os pesos da camada oculta para camada oculta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWE0nU4RxQp6"
      },
      "source": [
        "# Etapa 7: Avaliação do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIzocaIJ9fgv",
        "outputId": "7e666319-4aa9-473f-bc1c-3528c70e41b7"
      },
      "source": [
        "#colocando em modo de avaliação\n",
        "#gradiente e dropout sao desligados\n",
        "classificador.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=30, out_features=16, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv_TdW439fjv"
      },
      "source": [
        "x_test = transform_type(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMysUxwE9fm8",
        "outputId": "1db9fd82-5dd6-43ba-a98c-76cd71807df0"
      },
      "source": [
        "type(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udp7boEu9fpS"
      },
      "source": [
        "previsoes = classificador(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQcrWn_o-FSp",
        "outputId": "fcc4daa7-5000-44c8-8df6-744b474ef24d"
      },
      "source": [
        "#definir um limiar para classificação, se maior que 0.5 eh verdadeiro\n",
        "previsoes = np.array(previsoes > 0.5)\n",
        "previsoes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kS5SNgr-Fae",
        "outputId": "b55255f2-9f45-441e-f9e4-ac26dc8c2b50"
      },
      "source": [
        "taxa_acerto = accuracy_score(y_test,previsoes)\n",
        "taxa_acerto"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9090909090909091"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsxfa-Mu-FdU"
      },
      "source": [
        "matriz = confusion_matrix(y_test,previsoes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "GOfxj7ln_KdU",
        "outputId": "f485b03b-5b9d-44bb-c6d0-c5904edb4ae5"
      },
      "source": [
        "sns.heatmap(matriz,annot=True);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}